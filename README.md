# Patient_NoShowPredictor
# üè• Healthcare Patient No-Show Predictor

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.0+-orange.svg)](https://scikit-learn.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

A machine learning system to predict patient appointment no-shows, enabling healthcare clinics to implement targeted interventions and reduce costly missed appointments.

## üéØ Project Overview

**Problem:** Patient no-shows cost healthcare clinics an average of $150 per missed appointment, resulting in lost revenue, wasted resources, and reduced care access. With typical no-show rates of 20-30%, this represents a significant operational challenge.

**Solution:** Machine learning classification model identifying high-risk patients before appointments, achieving 72% ROC-AUC and enabling targeted reminder interventions.

**Impact:** Estimated annual savings of **$180,000+** for a mid-sized clinic through prevention of 1,200+ no-shows per year.

---

## üìä Results Summary

| Model | Accuracy | Precision | Recall | F1-Score | ROC-AUC |
|-------|----------|-----------|--------|----------|---------|
| **Gradient Boosting** | **0.72** | **0.68** | **0.75** | **0.71** | **0.72** |
| Random Forest | 0.70 | 0.65 | 0.73 | 0.69 | 0.70 |
| Logistic Regression | 0.68 | 0.62 | 0.70 | 0.66 | 0.67 |

‚úÖ **Best Model:** Gradient Boosting with 72% ROC-AUC  
‚úÖ **Training Dataset:** 110,527 appointment records  
‚úÖ **Class Balance:** Handled with SMOTE oversampling  
‚úÖ **Key Finding:** "Days in advance" is the strongest predictor (importance: 0.31)

![Model Performance](model_performance.png)

---

## üî¨ Methodology

### 1. Dataset
**Source:** [Kaggle - Medical Appointment No Shows](https://www.kaggle.com/datasets/joniarroba/noshowappointments)

**Records:** 110,527 patient appointments  
**Features:** 14 patient and appointment characteristics  
**Target:** Binary classification (Show/No-Show)  
**Class Distribution:** 79.8% showed up, 20.2% no-show

### 2. Feature Engineering

Created **10 new features** from raw data:

**Time-Based Features:**
- `DaysAdvance`: Days between scheduling and appointment (0-179 days)
- `DayOfWeek`: Monday (0) through Sunday (6)
- `IsWeekend`: Binary weekend indicator
- `ScheduledHour`: Hour appointment was scheduled
- `SameDay`: Flag for same-day appointments

**Patient Risk Features:**
- `AgeGroup`: Categorical age buckets (0-18, 19-35, 36-50, 51-65, 65+)
- `ChronicConditions`: Count of chronic conditions (0-4)
- `HighRisk`: Composite flag for high-risk patients
- `NeighbourhoodFreq`: Frequency encoding for location

**Demographics:**
- `GenderEncoded`: Binary gender encoding

### 3. Data Preparation

**Train-Test Split:** 80% train (88,421 samples), 20% test (22,106 samples)

**Class Imbalance Handling:**
- Original distribution: 79.8% / 20.2%
- Applied SMOTE (Synthetic Minority Over-sampling Technique)
- Balanced training set: 50% / 50%

**Feature Scaling:**
- StandardScaler normalization
- Mean = 0, Std = 1

### 4. Models Tested

**Baseline:**
- Logistic Regression with L2 regularization

**Ensemble Methods:**
- Random Forest (100 estimators)
- Gradient Boosting (100 estimators) ‚Üê **Winner**

**Evaluation Metrics:**
- ROC-AUC (primary metric - handles imbalance well)
- Precision, Recall, F1-Score
- Confusion Matrix

---

## üß† Key Findings

### Top 5 Predictive Features (by importance):

1. **DaysAdvance** - Importance: 0.31
   - Appointments scheduled >30 days in advance have 35% higher no-show rate
   - Sweet spot: 3-14 days in advance

2. **SMS_received** - Importance: 0.19
   - SMS reminders reduce no-shows by **18%**
   - Critical intervention point

3. **Age** - Importance: 0.15
   - Patients under 25 and over 65 have higher no-show rates
   - Young adults (19-25) highest risk group (28% no-show rate)

4. **NeighbourhoodFreq** - Importance: 0.12
   - Geographic patterns indicate transportation/access barriers
   - Low-frequency neighborhoods = higher risk

5. **HighRisk** - Importance: 0.09
   - Composite flag combining multiple risk factors
   - Identifies 32% of patients accounting for 51% of no-shows

### Surprising Insights

‚ùó **Chronic conditions (hypertension, diabetes) DO NOT increase no-show risk**
- Patients with chronic conditions are actually slightly more reliable
- Likely due to understanding importance of consistent care

‚ùó **Gender has minimal impact**
- Only 1% difference between male/female no-show rates

‚ùó **Scholarship status increases no-show risk**
- Patients on financial assistance programs: 25% no-show rate vs. 19%
- Suggests economic barriers despite subsidized care

---

## üí∞ Business Impact Analysis

### Financial Impact (Annual Projections)

**Assumptions:**
- Average clinic: 100 appointments/day, 250 days/year
- Cost per no-show: $150
- Model intervention success rate: 50% of detected no-shows prevented

**Current State (No Model):**
- Annual no-shows: 5,000 appointments
- Annual cost: **$750,000**

**With Model:**
- Detection rate: 75% (3,750 no-shows identified)
- Prevention rate: 50% (1,875 no-shows prevented)
- Annual savings: **$281,250**
- **ROI: 37.5% reduction** in no-show costs

### Operational Impact

üìû **Intervention Strategy:**
- **32% of patients** flagged as high-risk
- Daily high-risk patients: ~32 requiring intervention
- Recommended action: SMS reminder + follow-up call 24-48h before appointment

‚è±Ô∏è **Resource Allocation:**
- 15 minutes per intervention call
- 8 hours daily staff time for high-risk outreach
- Cost: ~$50K annually in staff time
- **Net savings: $231,250/year**

---

## üöÄ Quick Start

### Prerequisites
```bash
Python 3.8+
pip install -r requirements.txt
```

### Installation
```bash
git clone https://github.com/AshlynnFaithMoore/PatientNoShowPredictor.git
cd PatientNoShowPredictor
pip install -r requirements.txt
```

### Download Dataset
1. Visit [Kaggle Dataset](https://www.kaggle.com/datasets/joniarroba/noshowappointments)
2. Download `noshowappointments.csv`
3. Place in project root directory

### Run Complete Pipeline
```python
python noshow_predictor.py
```

This will:
- ‚úÖ Load and explore data
- ‚úÖ Perform EDA with visualizations
- ‚úÖ Engineer features
- ‚úÖ Train multiple models
- ‚úÖ Generate performance visualizations
- ‚úÖ Calculate business impact

### Expected Output
```
========================================================
PATIENT NO-SHOW PREDICTION MODEL
========================================================

üìä LOADING DATA...
Dataset Shape: 110,527 rows √ó 14 columns

üìà NO-SHOW DISTRIBUTION:
  Showed Up: 88,208 (79.8%)
  No-Show:   22,319 (20.2%)

üèÜ BEST MODEL: Gradient Boosting (ROC-AUC: 0.720)

üí∞ FINANCIAL IMPACT:
   Current annual cost:     $750,000.00
   Estimated annual savings: $281,250.00
   ROI: 37.5% reduction in no-show costs
```

### Generated Files
- `eda_analysis.png` - Exploratory data analysis visualizations
- `model_performance.png` - Model comparison and metrics

---

## üìÅ Project Structure

```
PatientNoShowPredictor/
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ noshowappointments.csv    # Raw dataset (download from Kaggle)
‚îÇ
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_EDA.ipynb              # Exploratory analysis
‚îÇ   ‚îú‚îÄ‚îÄ 02_FeatureEngineering.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 03_ModelTraining.ipynb
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ noshow_predictor.py       # Main pipeline script
‚îÇ
‚îú‚îÄ‚îÄ results/
‚îÇ   ‚îú‚îÄ‚îÄ eda_analysis.png          # EDA visualizations
‚îÇ   ‚îî‚îÄ‚îÄ model_performance.png     # Model results
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt               # Python dependencies
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ LICENSE
```

---

## üìà Visualizations

### Exploratory Data Analysis
![EDA Analysis](eda_analysis.png)

Key insights:
- Age distribution shows two peaks (young adults and middle-aged)
- SMS reminders significantly reduce no-shows
- Weekend appointments have slightly higher show rates

### Model Performance
![Model Performance](model_performance.png)

Includes:
- ROC curves comparison
- Precision-Recall curves
- Feature importance analysis
- Confusion matrix

---

## üîÆ Future Improvements

### Short-term (1-2 months)
- [ ] **Hyperparameter Tuning:** GridSearchCV for optimal parameters
- [ ] **Additional Features:** Weather data, traffic patterns, provider specialty
- [ ] **Model Explainability:** SHAP values for individual predictions
- [ ] **A/B Testing Framework:** Test intervention strategies

### Long-term (3-6 months)
- [ ] **Deep Learning:** LSTM for sequence modeling (patient history)
- [ ] **Multi-output Prediction:** Predict cancellation likelihood + optimal reminder timing
- [ ] **Real-time API:** Flask/FastAPI deployment for clinic integration
- [ ] **Dashboard:** Streamlit app for daily high-risk patient lists
- [ ] **Cost-sensitive Learning:** Optimize for business metrics not just accuracy

### Integration Ideas
- [ ] **EMR Integration:** Pull data directly from Epic/Cerner
- [ ] **Automated Reminders:** Trigger SMS/calls for high-risk patients
- [ ] **Scheduler Optimization:** Overbook based on no-show predictions
- [ ] **Patient Portal:** Show personalized tips for keeping appointments

---

## üõ†Ô∏è Technologies Used

- **Python 3.9**
- **Data Processing:** pandas, NumPy
- **Machine Learning:** scikit-learn, imbalanced-learn (SMOTE)
- **Visualization:** matplotlib, seaborn
- **Environment:** Jupyter Notebook

---

## üìö Key Learnings

### Technical Insights
1. **Class imbalance is critical** - SMOTE improved minority class recall by 23%
2. **Feature engineering > model complexity** - Simple features outperformed complex ones
3. **Domain knowledge matters** - Healthcare experience guided effective feature creation
4. **Evaluation metrics must match business goals** - ROC-AUC better than accuracy for imbalanced data

### Healthcare Domain Insights
1. **Behavioral patterns are predictable** - Scheduling behavior reveals attendance likelihood
2. **Intervention timing matters** - 24-48h before appointment is optimal
3. **Economic factors dominate** - Transportation/access barriers > health status
4. **SMS is cost-effective** - 18% reduction for minimal cost

---

## üìñ References

1. Dantas et al. (2018). "No-show in appointment scheduling - a systematic literature review"
2. Kheirkhah et al. (2015). "Prevalence, predictors and economic consequences of no-shows"
3. Kaggle Dataset: [Medical Appointment No Shows](https://www.kaggle.com/datasets/joniarroba/noshowappointments)
4. scikit-learn: [Classification Documentation](https://scikit-learn.org/stable/supervised_learning.html)

---

## üë§ Author

**Ashlynn Moore**
- GitHub: [@AshlynnFaithMoore](https://github.com/AshlynnFaithMoore)
- LinkedIn: [linkedin.com/in/ashlynnmoore](https://linkedin.com/in/ashlynnmoore)
- Email: ashlynnfaith22@gmail.com

**Background:** Healthcare data analyst with experience in FMLA case management and patient services at Proliance Orthopaedics. Combining domain expertise in healthcare operations with machine learning to solve real clinical problems.

---

## üôè Acknowledgments

- Proliance Orthopaedics and Sports Medicine for inspiring this project through real-world challenges
- Kaggle community for providing the dataset
- Women in Tech mentorship program for support and guidance

---

## ‚≠ê Star This Repository

If you found this project helpful for learning healthcare analytics or machine learning, please consider giving it a star! It helps others discover the work.

---

**Note:** This is a portfolio/academic project demonstrating data science skills. For clinical deployment, consult with healthcare administrators, ensure HIPAA compliance, and conduct thorough validation studies.
